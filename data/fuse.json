{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Home","n":1},"1":{"v":"\n## Where knowledge can grow!\n\nA collection of thoughts and articles at different development stages: from seedlings to ever-greens.\n\n[[Blender's Video Sequence Editor|vse]]\n\n[[QGIS: creating a globe map|qgis.globe]]\n\n[[QGIS: creating a travel map|qgis.travel-map]]\n\n[[ExifTool|exiftool]]\n\n[[Integration of Audacity with VSE|vse.audio]]","n":0.174}}},{"i":2,"$":{"0":{"v":"Qgis","n":1}}},{"i":3,"$":{"0":{"v":"Globe","n":1},"1":{"v":"Did you ever need a locator globe map to illustrate your magnificent trip of the last holidays? There are, of course, plenty of globe maps on the internet; e.g. [Wikimedia SVG's](https://commons.wikimedia.org/w/index.php?search=world+globe&title=Special:MediaSearch&go=Go&type=image&filemime=svg). But to find just that one you have in mind; from the right perspective? It *should* be rather easy to create your own locator globe with exactly that look and feel that you wish with those two great open-source tools: [QGIS](https://www.qgis.org/) and [Blender](https://www.blender.org).\n\nMy first attempt -with Blender and QGIS- was successful and rather uncomplicated. Another (supposedly simpler) technique -only within QGIS- resulted in a pile of problems and work-arounds.\n\n# Creating a locator globe with Blender and QGIS\n\nStart Blender and create a new project. Replace the default cube with a UV Sphere. Switch to the Material or Rendered Preview with Viewport Shading buttons (top right). Now, you need a texture map to cover the sphere. You could try to download an image from internet; there are plenty available. Search for \"texture world map\". Or, you could generate one to your liking with QGIS.\n\nThe easiest way is to use the built-in world map from QGIS. Just enter the word \"World\" in the coordinate box in the middle of the status bar at the bottom (see figure 1). This world map is flat, grey-styled map with all the countries of the world outlined. Of course, you can customize it to your liking; see [[Improvements|#improvements]] \n\n![](assets/images/_qgis-worldmap.svg)\nFigure 1: QGIS with the QIS World Map layer\n\nThen, you need to export this image as a PNG. Choose the menu Project > Import/Export > Export Map to Image and select Calculate from Layer (World Map) to define the size of the image.\n\nSwitch to Blender and assign this image as a texture for the sphere. Select the Material Properties tab in the Properties panel and add a new material. Replace the Base Color with the image: click on the yellow button next to Base Color to add an Image Texture and assign the exported image from QGIS with the Open button. If you need this image, you have to render it out.\n\n![](assets/images/blender-screenshot.svg)\nFigure 2: Blender with textured sphere.\n\n\n## Improvements\n\nFirst of all, there is in fact a slight problem with the UV Unwrapping (but you probably won't see it on this small scale). If you switch to the UV Editing workspace and select the sphere in Edit mode, you will notice two rows of triangles in the UV map. This is because the sphere is closed at the top and bottom. The result however is that a square area of the flat world map will be squeezed into a smaller triangle. This is not optimal and will result in distortion. But again, at the polar regions, you probably won't notice it. There are a few work-arounds; see for example [Mastering Blender](https://www.youtube.com/watch?v=72hgMoyTbXE&t=116s).\n\nThe surface of the sphere is by default made of 16 x 32 flat faces. They are very noticeable in figure 2. You can smoothen the surface by applying a Subdivision Surface Modifier (see for example [5 minutes Blender](https://www.youtube.com/watch?v=Y99L5YC-Uw0from)).\n\nAnd, of course, you can animate the globe, for example simulating the earth rotation and create some day-and-night animation.\n\nImprovements of the map (e.g. coloring) should be done in QGIS. A small enhancement is the coloring of a specific country of interest. If you select the World map layer and press F6 (Open attribute Table); you will notice that each country has a full name and three-letter abbreviation (ISO-A3). You can use this field to apply a rule-based styling to this layer. In the Layer Styling panel, select the World Map and change the \"Single Symbol\" styling to \"Rule Based\". Create a new rule and insert the text ```\"ISO_A3\"  =  'ESP'``` into the Filter text box to style the country Spain (ESP). ISO_A3 has to be surrounded by double quotes and ESP by single quotes. You can build the formula with the Ɛ button next to it.\n\nIf you need more sophisticated maps, you also need more sophisticated data sets.  A very good starting point for global data are the free vector and raster map data from [Natural Earth](https://www.naturalearthdata.com/). For a locator globe, you don't need very detailled data; a scale of 1:110m is sufficient (1 to 110 million or 1 cm = 1,100 km). So, you can start with the following files \n\n- Land: ne_110m_land.zip [link](https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/physical/ne_110m_land.zip)\n- Ocean: ne_110m_ocean.zip [link](https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/physical/ne_110m_ocean.zip)\n- Graticules at 15° interval: ne_110m_graticules_15.zip [link](http//www.naturalearthdata.com/download/110m/physical/ne_110m_graticules_15.zip)\n\nYou need the last file to create the graticules (parallels & meridians). You don't have to unzip the files. QGIS can work right away with the zip files. Start QGIS and drag the zip-files to the Layers panel (see figure 1). Note that only the shp-file is added to the Layers panel. QGIS is a layered application such as GIMP or Inkscape. This means that if the graticule layer is below the land and/or ocean layer, it will not be visible. You can change the Layer Style in the Properties panel at the right hand side.\n\nOne downside of the current technique is that you need two programs and/or a bunch of intermediate files.\n\n# Creating a locator globe with QGIS ONLY!\n\n*Isn't it possible to create a locator globe map within QGIS alone?* Of course! A quick search on the internet (\"how to create a globe in QGIS\") produced several solutions; e.g [cartographyclass.com](https://cartographyclass.com/a-world-locator-map-in-5-minutes/) and the excellent tutorial (in Dutch) from [Geojuffie](https://www.youtube.com/watch?v=BXtZlTPlMj8). They all have in common that you need to create a specific Coordinate Reference System (CRS). A CRS defines how the two-dimensional, projected map in your GIS relates to real places on the earth. In this case, the two-dimensional map however resembles a globe (but still is a two-dimensional map). This is a two step technique.\n\n- Create the custom CRS with the menu Settings > Custom Projections. In the Name field, you can enter the name of your CRS e.g. myGlobe. In the Format > Project String, you need to enter the commands to create a so-called azimuth orthographic projection, e.g.\n\n  ```(1) +proj=ortho +lat_0=42.53 +lon_0=-72.53 +ellps=sphere +units=m +no_defs```\n\n  or alternative version\n\n  ```(2) +proj=ortho +lat_0=21 +lon_0=6 +a=6371000 +b=6371000 +units=m +no_defs```\n\nWith this command, you will create an orthogonal projection, where the focus of the map will be placed at coordinate (42.53; -72.53) of the real earth. The projection itself is an a sphere or alternatively, you specify that the globe has a radius of 6371000 m.\n\n- Switch the project to the just created CRS with the menu Project > Properties or the CRS box in the statusbar below (right hand corner).\n\nAnd like so many tutorials, they all produce very nice results as long as you follow them precisely. Of course, you want a map, tailored to your needs. And then it started to go wrong.\n\nMy first map was based on the Natural Earth land and ocean maps. I used the following projection command.\n\n```+proj=ortho +lat_0=21 +lon_0=6 +x_0=0 +y_0=0 +a=6371000 +b=6371000 +units=m +no_defs```\n\nFigure 3 shows the result; which is not at all perfect.\n\n![](assets/images/QGIS-test-1-custom-crs.svg)\nFigure 3: My first attempt to produce a globe.\n\nNotice that parts of America and Asia are gone, as was the color of the ocean! What did I do wrong? My first reaction (googling), opened once again the box of Pandora and let me drown in the endless ocean of the internet. Some impressions of my voyage.\n\n1. A reasonable explanation (at that time in the exploration) came from [Avenza.com](https://www.avenza.com/resources/blog/2019/01/14/orthographic-projections/). With the globe projection, you always see only half of the flat map. The other half is hidden behind the horizon. So, the QGIS projection command should hide those lines.\n\n2. But how? I first tried to erase the points in the flat map that weren't visible in the globe view in a rather sketchy way. Of, course, you have to do this on the rectangular map; not the globe. With the Vertex Editor, you can delete points from the polygons. Very soon, there appeared straight lines. If you delete points, QGIS will connect the remaining ones automatically on a closed polygon. And there, it should have become clear to me what the fundamental problem was. But unfortunately that wasn't the case. My map improved a bit; so I decided to delete more precisely the points that were on the hidden half.\n\n3. How can you know which points will be visible after the reprojection. A very big work-around was to introduce blender once again. Create the [globe in Blender]({{ref #Creating a locator globe with Blender and QGIS}}). Rotate the globe to your liking. Switch to the UV Editing workspace. Select the globe in Edit mode and select all visible points. They will light up them in the UV map. You can add a Bezier circle around the globe to make it more precise. Make a screenshot of the UV map and import that UV map in QIS. Et voila, there you have a precise collection of all the points you have to delete.\n\n4. A minor problem was that the size of the QGIS and Blender map aren't the same. So, you have to move & scale the UV bitmap so that it aligns with the shp-layer. Hm, how? After googling \"qgis scale move a bitmap\", it turns out that you need a plugin for that (Freehand Georeferencer).\n\n5. Edit the shp-layer and remove the points that are not visible from your perspective. Once again: some obstacles. The land and ocean layer came from a downloaded ZIP-file. Apparently, that kind of layer could not be edited but there is not much info about that. Ultimately, I succeeded to export the layer (Layer > Save AS). This exported layer then could be edited with the Vertex tool.\n\n6. Perhaps -I thought- the detour with Blender isn't necessary. May be, I can draw a circle within QGIS itself. After one more Google search (try \"QGIS add circle\"), I needed a memory layer (nowadays called Scratch layer) and the \"Digitizing toolbar\". But, this toolbar was greyed out (inactive). You can't draw a circle on a globe projection. By then, I  realized that I didn't know where to draw the circle on the flat map. So, that's a dead end, once again.\n\n7. At last, I thought having found THE solution: a post that exactly describes the problem at [StackExchange](https://gis.stackexchange.com/questions/78346/ortho-projection-produces-artifacts). I need a plugin called [Clip to Hemisphere](https://github.com/jdugge/ClipToHemisphere). But, again. A death end. An error pops up: ne_110m_land.shp has an invalid geometry. This is the point where it started dawning on me. There were less problems with other data sources and center points; for example the built-in world map of QGIS (also a tip from [Geojuffie](https://www.youtube.com/watch?v=BXtZlTPlMj8)) gives most of the time acceptable results. The ocean layer was in fact not necessary; it's the complement of the land layer. At that moment, I also discovered the Globe Builder plug-in and observed that this plugin uses the country layer of Natural Earth as base.\n\nAs far as I understand it now (but this is a seedling post in my digital garden!), the land layer contains very large polygons; spreading over multiple continents. The chance that one or more polygons extend in the hidden part of the orthographic projection is significant. QGIS can not draw these closed polygons. Some of the vertices are on the backside of the globe. They shouldn't be visible. Drawing this closed polygon is not possible. So, QGIS deletes it from view; e.g. parts of America and Asia in figure 4.\n\nOK. But, how to solve it? By then, I have discovered the Globe Builder plugin.\n\n\n## The easy and better way!\n\nInstall the plug-in \"Globe Builder\": menu Plugins > Manage and Install Plugins ... Select All and search for Globe Builder. The plugin creates a separate panel that you can make visible with menu View > Panels > Globe Builder. If you want the globe right away, click on Add the Globe to a Map at the bottom! But perhaps, it's better to take the following steps to get a better understanding.\n\n![](assets/images/QGIS-plugin-globe-builder.png)\nFigure 3: Worldmap with graticules created with plugin Globe Builder.\n\nIf you haven't already a map downloaded, the plugin can \"Load Data to a Map\" from the Natural Earth website. But, remember, not all maps are suitable for orthographic projection. If you should try it with the same Land layer and center coordinates as in figure 3, you will get the same -distorted- result.\n\nWith the plugin, you can choose between the 50m or 110m scale and some graticules. It will download the Countries layer from Natural Earth. The checkbox \"Sentinel-2 cloudless adds a more colorful and photographic appearance of the earth surface. A group \"Globe\" is created with the layers Countries (from Natural Earth), and/or Graticules and S2 Cloudless (depending on the selected options). The assigned CRS is EPSG:4326 - WGS 84 (flat map).\n\nThen, you can choose the Projection method. Under the hood, the coordinate transformation within QGIS is done with the [open-source software PROJ](https://proj.org/index.html). A complete list of the about 150 projections is found [here](https://proj.org/operations/projections/index.html). With the Globe Builder plugin, you can choose between 5 options.\n\n| Projection  | Example     |\n| :---        |    :----:   |\n| [Azimuthal Orthographic](https://proj.org/operations/projections/ortho.html) (default): the earth is projected on a flat plane, positioned tangentially at a given center position from a light source at infinite distance. This projection gives you the wanted globe view.      | ![](assets/images/azimuthal-projection.png)|\n| [Equal Earth ](https://proj.org/operations/projections/eqearth.html)  Like the name implies, this projection retains the relative size of areas. It is [invented](https://en.wikipedia.org/wiki/Equal_Earth_projection) in 2018.   | ![](assets/images/equal-earth-projection.png) |\n| [Hammer & Eckert-Greifendorff](https://proj.org/operations/projections/hammer.html) is also an [equal-area map projection](https://en.wikipedia.org/wiki/Eckert-Greifendorff_projection) described by Max Eckert-Greifendorff in 1935.   | ![](assets/images/hammer-Eckert-projection.png)|\n| [Aitoff](https://proj.org/operations/projections/aitoff.html) is a modified azimuthal map projection proposed by [David A. Aitoff](https://en.wikipedia.org/wiki/Aitoff_projection) in 1889.   | ![](assets/images/aitoff-projection.png)  |\n| [Eckerty I](https://proj.org/operations/projections/eck1.html)  According to [ArcGIS](https://pro.arcgis.com/en/pro-app/latest/help/mapping/properties/eckert-i.htm), the Eckert I projection is a compromise pseudocylindrical map projection with rectilinear meridians and an odd appearance. The projection is simple, but it has no practical use other than making a world map with an unusual shape.   | ![](assets/images/eckert-projection.png)|\n|\n\n\n\nAfter setting the projection method, create the globe view with the Center button from \"Center the globe based on:\" panel. But, what exactly is meant by \"center the globe\"? The Globe Builder plugin uses by default the Azimuthal Orthographic projection to create the globe. A flat plane (in contrast to a cylinder or cone) is used to project the earth surface to. It's called Orthographic because the light source is set at infinity, resulting in orthogonal parallel projection lines from the earth globe to the flat surface. The flat plane is positioned tangentially at a give position (for example the North pole). This point is the center point and will appear in the middle of the projected circle. Because this center point is only useful in a orthographic projection, the option is only available for the first (Azimuthal Orthographic) projection method and greyed out for the others. The four options are: \n\n- Geocoding: perhaps the easiest way. Enter the name of a place (e.g. New York), click search, select the correct place if there are multiple locations and click center to change the globe view. You can display up to max 5 addresses to choose from.\n- Coordinates, you can set the midpoint of the orthogonal projection (=circle) to the specified lon + lat combination. For example, to have the country Spain at the center of the globe map, enter the coordinates of Madrid (lon=-3.70, lat=40.41). Please, note that due to the perspective view, this doesn't look correct. However, the chosen coordinate is indeed the midpoint of the *circle* of the globe map. You can always alter the center point by entering new coordinates and clicking Center.\n- Center of the current view. For example, you can zoom in on Iceland to make that country the center of the globe.\n- Layer: each layer map has a center; for example the Natural Earth maps have a center point somewhere in the Atlantic Ocean (coordinates 0,0).\n\nWith the the visualization panel, you can change colors and add a Halo effect (= colored ring around the sun or a planet). This Halo effect greatly enhances the optical illusion of perspective from outer space. With the [layout panel](https://docs.qgis.org/3.22/en/docs/user_manual/print_composer/index.html), you can create the globe map into a new Layout; which can be handy when you want to create inset maps.\n\nThe last two buttons (Add the Globe to a Map and Add the Globe to a Layout) are shortcuts to create the globe in one step.\n\nThis plugin makes it really easy to create high-quality globe maps. I found it through the enlightening post of [Alasdair Rae](http://www.statsmapsnpix.com/2019/09/globe-projections-and-insets-in-qgis.html) (2019). The code is at [Github](https://github.com/GispoCoding/GlobeBuilder). One last warning, the created Halo and graticule layers are Scratch layers, meaning that they only exist in memory and will not be preserved upon saving the project. If you want these layers for latter use, you have to save them manually. The Countries layer was downloaded upon installing the plugin and is located in your user folder as a geojson file (that's why it goes so fast).\n\n","n":0.019}}},{"i":4,"$":{"0":{"v":"VSE","n":1},"1":{"v":"Blender is a versatile open-source software used for modeling, sculpting, 2D drawing, animation, and video editing. Its video editor is a basic but robust editor; tightly integrated with the other parts of the Blender ecosystem. Upon opening Blender, the [splash screen](https://docs.blender.org/manual/en/dev/interface/window_system/splash.html) gives you the possibility to create a *Video Editing* project. Choosing this option takes you immediately into the Video Editing workspace.\n\n![](/assets/images/vse-splash-screen.svg)\n\nWorkspaces are predefined window layouts aimed at a specific use case, for example video editing. Each Workspace consists of a set of *Areas* containing one or more *Editors*. The Video Editing workspace is a smart combination of five editors. Together they provide you with all the necessary tools to edit your videos.\n\n![](/assets/images/vse-workspace.svg)\n\n(1) File browser: you can navigate your file system for easily adding assets (clips, images, sounds, ...) to your timeline by dragging and dropping the files. If you select multiple files, they will be added one after the other to the timeline. You can customize (sorting, filtering, ...) the file browser, so that you have an optimal overview of your assets. Of course, there are more methods to add content to your timeline.\n\n(2) & (4) Video Sequencer: the areas (2) and (4) both contain the Video Sequence Editor; respectively with type Preview and type Sequencer. The Preview is self-explanatory. It shows you the image of the current frame in the Sequencer Timeline. The Sequencer type is probably the area in the workspace that you'll use the most. The Sequence Editor has three view types: *Sequencer*, *Preview*, and *Sequencer & Preview*. You can switch easily between the Sequencer and the Preview with the {Ctrl + Tab} shortcut\n\n(3) Properties: are organized into several categories, which can be chosen via tabs (the icons column to its left). Not all categories are relevant in the Video Sequencer. By default only the following are shown: Active Tool, Render Properties, View Layer Properties, Scene Properties, World Properties, and Texture Properties. Most of the time, you will use only the Render Properties.\n\n(5) Timeline: only the header of this editor is visible; so you have to drag the horizontal top border to reveal the time units and eventual keyframes. The Timeline Editor is also used in other workspaces. The use of this Timeline Editor within the Video Editor workspace is rather limited and a case could be made to remove it from the workspace. Its functions can easily be overtaken by the Sequencer (see figure 2), which is right on top of it in the Video Editing Workspace.\n\nThe built-in Video Editing workspace is very handy and it can be customized easily. Each editor area can be sized, moved, replaced or removed from the workspace. As example, an alternative workspace with auto-installed add-ons can be download from [tin2tin's github](https://github.com/tin2tin/Sequence_Editing>). A screenshot is provided in figure 2.\n\n![](https://raw.githubusercontent.com/tin2tin/Sequence_Editing/main/Sequence_Editing.png)\n\nPlease, note that the Timeline editor -area (5) in figure 2- is removed and that the Playback controls are placed in the header of the Sequencer. Several add-ons are automatically installed (e.g. Transform tools), together with some new operators (e.g. Remove Gap after ...). Last but not least, the Properties editor is also removed and the project settings are placed in the Preview sidebar, where they can easily toggled on/off with the N-key.\n\n","n":0.043}}},{"i":5,"$":{"0":{"v":"Working with masks in the VSE","n":0.408},"1":{"v":"# Creating a circular mask with a border\n\nImagine that you need a red circle with a blue border on a green background. Or an enlarged circular cut-out of a family photo.\n\n![](/assets/images/vse.mask.svg)\nFigure 1: Creating a blue bordered mask.\n\n- Create the mask in the image editor. Call it for example msk-circle. The Image Editor is opened in the top-left window of figure 1. Don't forget to switch to the Mask Editing Context (see top-left). By default, it is set to View.\n- Switch to the Sequencer of the VSE (lower panel). You need three strips:\n   - the background strip; e.g. the family photo or the green color strip in figure 1.\n   - the masked strip; e.g. the image of the face or the red color strip.\n   - the border strip; e.g. probably always a color strip. We choose a blue color for the border. Note that the border strip is beneath the masked strip but above the background.\n- Apply the mask (msk-circle) to both the border and masked strip. For now, you will only see a completely red circle without a border. This is because the same mask is applied to both and the red strip is on top of the blue one. You need to scale up the blue strip a bit, BUT ...\n- Scaling the blue strip will have no effect because you don't scale the mask with it. You need to convert the strip into a meta strip (right click and choose Group). Because you probably will scale or move both strips, it is good practice to also group the masked strip.\n- Scale the blue border strip a little so that it appears from under the masked strip. Depending on the width of the border you have to scale more or less.\n- Eventually, select both group strips and scale, rotate or move them to the appropriate values. \n\n\n# Creating a growing arrow with masks\n\n- Render the frame where the arrow will finish\n- Draw the arrow as a mask in the image editor. Place the render result of the previous step as background image. Ctrl+Shft click to add points. Make sure to Toggle Cyclic to close the shape.\n- Swith to the VSE. Insert a color strip with the desired length. Apply the mask. The arrow will appear. Eventually convert the strip to a Group (Ctrl+G) and scale, rotate and move the arrow to the desired spot. \n- Place the current frame at the frame where the arrow should be fully visible.\n- Insert a keyframe for the X/Y location and/or the crop left/right or top/bottom. This depends on the direction of the growing arrow (from left to right or top to bottom).\n- Place the current frame at the frame where the growing of the arrow should begin.\n- Change the crop value until the arrow is completely disappeared. Move the box of the arrow to the starting postion .\n- Put a keyframe on the crop value and x/y location.\n\n- eventually, leave the arrow at the end position. Crop it to zero. Reduce  the x/Y position with the crop value\n","n":0.044}}},{"i":6,"$":{"0":{"v":"Integrate voice-over with background music","n":0.447},"1":{"v":"Finally. Your edited movie is almost finished. You have just added some background music and environmental (ambient) sounds. Now, it's time to add the narrative voice or voice-over. These voice-over fragments are probably distributed irregularly along the timeline. In order to understand the narrative well, you should lower the volume of the background music a bit while talking. This is called ducking (see figure 1).\n\n![](/assets/images/vse.audio.svg)\nFigure 1: Graph Editor window (left) with keyframed Volume (right) of the background music strip.\n\nYou can do this manually by keyframing the volume of the music strip.\n\n- Select the background music strip. Set the playhead (current frame) at the beginning of the voice-over; e.g. around 00:20' in figure 1.\n- Hover over the volume field with the mouse in the side panel (right) and press the shortkey I (the letter I) or click at the small circle at the right of the field. This will set a keyframe.\n- Move the playhead a few frames to the right. Lower the volume (around 0.6 in figure 1) and keyframe again (press I).\n- Repeat the last two steps in reverse at the end of the voice-over (around 00:40' in figure 1). If you have Display Waveform turned on, you will see the result immediately (see figure 1 - middle panel).\n\nOf course, this is a lot of work and error-prone. Also, if you should move the voice-over strip in the timeline, you have to reverse the volume changes. Fortunately, this ducking could be accomplished automatically with [Audacity](https://www.audacityteam.org/), a free, open source, cross-platform audio software. You may also need a Blender add-on [Audacity tools for Blender](https://github.com/tin2tin/audacity_tools_for_blender) to transfer the audio-strips from Blender to Audacity and back again.\n\n# Without the add-on\n\n- Export each audio channel of your project individually. To export the background music channel of figure 1, you have to disable the voice-over channel.\n- Select the menu Render > Render Audio. Apply the appropriate values for container, bitrate, ...\n- Import each file in Audacity. You have to place the Background music in the top channel and the voice-over right beneath it. Be sure that you have the Music channel selected.\n- Apply the ducking with the menu Effects > Auto Duck. The [default values](https://manual.audacityteam.org/man/auto_duck.html) are quite smart.\n\n# With the add-on Audacity tools for Blender\n\n- Install the add-on. You can find the source-files at [tin2tin's github](https://github.com/tin2tin/audacity_tools_for_blender). Don't forget to specify the Audacity Executable (location); e.g. C:\\Program Files\\Audacity\\Audacity.exe in a Windows machine. Note also the warning in the add-on info panel: \"Before running this add-on, Audacity must be running with the Preferences > Modules > mod_script_pipe Enabled\".\n- Start Audacity and switch to Blender. Select the audio strips, you want to transfer and click the button `Send Selection` in the sidebar. With `Selection`drop-down, you can choose between strip (the active strip with white border in figure 2), `Selection` (the selected strips), `Sequence` (all audio strips) and `Record` (if you have a microphone available; Audacity will start recording).\n\n![](/assets/images/vse.audio.addon.png)\nFigure 2: Blender with some audio strips and the Audacity Tools panel visible (right).\n\n- Switch to Audacity. The selected audio strips should be available. The result of `Send Selection` will look like figure 3. Note that the audio strips are placed at the appropriate time slots. \n\n![](/assets/images/vse.audio.audacity1.png)\nFigure 3: Result within Audacity of the `Send Selection` command in Blender.\n\n- Apply the Auto Duck effect. As you can see in figure 4, the background music volume is lowered while the voice-over is playing with about 10 dB (default value).\n\n![](/assets/images/vse.audio.audacity1.png)\nFigure 4: Result of the Effect > Auto Duck command with default values.\n\n- The effect kicks in about half a second before the voice-over starts and fades out for about 1 second after the voice over finishes (see figure 5). The music will be lowered with 10 dB.\n\n![](/assets/images/vse.audio.audacity3.png)\nFigure 5: Default values of the Auto Duck effect.\n\n- After applying the Auto Duck in Audacity, you can transfer the result back to Blender with the Receive Mixdown button (see figure 2). In reality, the Audacity Tool has saved the result in a separate file in the active directory that you can import. Please, don't forget to mute or delete the original sound tracks; otherwise you will increase the sound level heavily.\n\nPlease note that the tracks must be in the correct order: background music on top and right beneath it the voice-over. It's a good habit to have this order also in Blender. For example:\n\nChannel 1: Blanc\nChannel 2: blanch\nChannel 3: Audio strips, associated with the movie strips from channel 5\nChannel 4: Background music. The will probably cover the entire timeline consecutively.\nChannel 5: Regular movie strips (visual). The audio part is automatically placed in channel 3 while importing, because channel 4 is already occupied with the background music.\nChannel 6 - 9: other movie strips and visual special effects.\nChannel 10: subtitles.\n\nWhile you are in Audacity, it is probably wise to also Normalize your audio and to set some peak levels for the different audio media. For example the background music shouldn't dominate and probably set at a volume level of about -20 dB. While, the voice-over could be set at a peak level of about -6 dB. Normalizing is also one of the many effects you could use in Audacity (menu Effects > Normalize).\n\nIt's possible to record/create macro's in Audacity that will execute the above commands automatically.\n","n":0.034}}},{"i":7,"$":{"0":{"v":"Exif","n":1},"1":{"v":"\nSometimes you need to know the date and time a photo is taken or a video is recorded. Nowadays, digital cameras store these metadata within the file itself, next to the actual image, or in an external file (sidecar). Typical metadata elements are: date and time the photo was taken, location, camera brand, camera setup (aperture, shutter speed), ... There are a few standard types of metadata: Exif, XMP, IPTC, and Dublin Core; see [PhotoMetadata.org](https://photometadata.org/META-101-metadata-types) for an in-depth review. Sometimes, the metadata is absent or deleted or incorrect.\n- You have scanned the photo from paper or the video from film. Maybe the development date is printed at the back of the photo or is reflected in the filename e.g. 20230431_135520.jpg. But, how can you transfer these dates into the metadata?\n- You have imported the digital images from a source that has deleted the metadata. For example, Whatsapp & Facebook will remove the date & time (and other info) at the time you upload the material. The name of the file gives you no clue what-so-ever; see figure 1. Other services will keep the metadata but make other changes. For example, uploading photos & videos to OneDrive will give you filenames like YYYYMMDD_HHMMSS, based on the available metadata or upload date. GooglePhotos will not change the original filename (e.g. img_1314.jpg) but will add a so-called side car file next to your photo or video with the same name (e.g. img_1314.jpg.xmp ). This sidecar contains either the date/time info from the original image and/or the date/time of uploading the file to the Google services. It will also convert your \"live\" (iPhone) photo to a small mp4-video.\n- The settings of your camera weren't correct at the time of recording. The metadata then, of course, will also no be correct. For dates, if you know the time of a particular recording however, you can always recalculate the other info by adding or subtracting time.\n\nOn top of that, there is no universal agreement on the naming and interpretation of the possible metadata fields, in particular the date/time fields: are we talking about the date/time the photo is taken, is processed, is stored, ...? Certainly for videos, you are in nowhere land. So, it's up to the software you are using (Digikam, XnView, Faststone, ...) how to manage these metadata. And also here is the quality of service very also very uneven.\n\n# How discover all dates in your photo or video\n\nYou need the open source software [Exiftool](https://exiftool.org/). For video files, the [MediaInfo](https://mediaarea.net/en/MediaInfo) app is also widely used.\n\nTo install ExifTool, you can follow the nice tutorial of [Q-tips](https://youtu.be/j9osB_eRuCU?t=93); start at 1:33. Suppose you have two files in a test-folder: IMG_4397.JPG and IMG_4392.MOV (both shot with an iPhone).\n\nIn Windows, you can right-click on a file and select Properties. For a JPG, this will reveal a Date Taken field. For the MOV, you can get (sometimes) a Media Created field under the Details tab. There are however much more date fields and these are also not the standard names. The following exif-command shows all date/time related info from a photo or video.\n\n`exiftool -time:all -groupNames -short IMG_4397.JPG`\n\n-time:all is a shortcut for all time-related fields. -groupNames will print the name of the group in front of the fields. -short will print the tag names in stead of the longer tag descriptions. The output for a typical jpg file is as follows.\n\n![](/assets/images/exif-jpg-time-all.png)\n\nFigure 1: Output of exif command for a typical jpg-file .\n\n# Rename the Google TakeOut files in a YYYYMMDD_HHMMSS format\n\nIf you store your photos and videos on Google Photos, there is a less known feature, called [Google TakeOut](https://takeout.google.com/). Besides downloading your photos and videos (without any size limit as in the regular download), it provides you with some additional benefits such as save-guarding your face recognition data and the upload date. The latter could useful in case the source service (e.g. WhatsApp, Facebook) has deleted the metadata).\n\nYou probably don't want to download all of your photos, so, it's better to create beforehand some albums e.g. one album per year or per month. Then, head to the Google TakeOut website, select the option Google Photos and your album. Wait for a ready-mail and download the zip-file. A typical TakeOut of iPhone material is:\n\n![](/assets/images/google-take-out.png)\nFigure 2: Typical output from Google Take Out.\n\nFor each image or video, there is an accompanying sidecar JSON-file. The files with the weird names (0100E3....) are from WhatsApp. The sidecar JSON contains the following data.\n\n```json\n{\n\"title\": \"0100E30E-AA4F-4D02-A1E8-727A4107063D.mov\",\n\"description\": \"\",\n\"imageViews\": \"2\",\n\"creationTime\": {\n   \"timestamp\": \"1670266930\",\n   \"formatted\": \"Dec 5, 2022, 7:02:10 PM UTC\"\n},\n\"photoTakenTime\": {\n   \"timestamp\": \"1667502010\",\n   \"formatted\": \"Nov 3, 2022, 7:00:10 PM UTC\"\n},\n\"geoData\": {\n   \"latitude\": 0.0,\n   \"longitude\": 0.0,\n   \"altitude\": 0.0,\n   \"latitudeSpan\": 0.0,\n   \"longitudeSpan\": 0.0\n},\n\"geoDataExif\": {\n   \"latitude\": 0.0,\n   \"longitude\": 0.0,\n   \"altitude\": 0.0,\n   \"latitudeSpan\": 0.0,\n   \"longitudeSpan\": 0.0\n},\n\"people\": [{\n   \"name\": \"Marietta\"\n}],\n\"url\": \"\",\n\"googlePhotosOrigin\": {\n   \"fromPartnerSharing\": {\n   }\n},\n\"photoLastModifiedTime\": {\n   \"timestamp\": \"1670267176\",\n   \"formatted\": \"Dec 5, 2022, 7:06:16 PM UTC\"\n}\n}\n```\n\nThe geoDataExif are the original location but these data has been erased by WhatsApp.  As know, it is also possible to add a location within the Google Photos. This location is stored within the key geoData. It is also possible to use face recognition. The recognized faces are stored within the key people. Note that there are also three dates available: creationTime, photoTakenTime, and photoLastModifiedTime. The first and last one are the date and time the photo is downloaded. The photoTakenTime is more interesting. It contains either the date/time from the metadata of the photo OR -if absent as is the case for WhatsApp photos- the date/time that the photo is uploaded to the Google storage. If you are in the habitude to save a photo immediately upon receiving it from WhatsApp, then this Date/time field is an approximation of the original date/time the photo was taken.\n\nWith the following ExifTool command you can update the date/time fields of the exif metadata with the PhotoTakenTime field. The dot at the end of the command is necessary. It means that all files from the current directory (= .) should be processed.\n\n`exiftool --ext json -r -overwrite_original -tagsfromfile \"%d/%F.json\" -d %s \"-Alldates<PhotoTakenTimeTimestamp\" .`\n\nIf you want to change the filename to a format as YYYYMMDD_HHMMSS.xxx then you should run the following command.\n\n`exiftool --ext json -d %Y%m%d_%H%M%S%%-c.%%e \"-filename<CreateDate\" -overwrite_original .`\n\nIn case you don't want loose the connection between the JSON file and the corresponding photo or video, you need also change the name of the JSON file. This is done with the following command.\n\n`exiftool -ext json -d %s \"-filename<${PhotoTakenTimeTimestamp;$_=$self->InverseDateTime($_);DateFmt('%Y%m%d_%H%M%S%%-c.%%e')}\" -overwrite_original .`\n","n":0.031}}},{"i":8,"$":{"0":{"v":"About","n":1},"1":{"v":"I'm a retired psychology professor but still active computer nerd. I love to use and dissect software, in particular open-source software such as Blender, QGIS, ffmpeg, Exiftools and others.\n\nThis digital garden is my way of trying to stay on top of all that information and also a way of contributing to those lovely open-source projects.","n":0.135}}}]}
